{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest regressor for predicting the deep conversion value of peptide.\n",
    "\n",
    "### This notebook is try to develop a regression model to predict the DC value through random forest regressor. \n",
    "### It is divided into following two parts.  \n",
    "\n",
    "#### 1. Predicting the deep conversion value of tetra peptides with only the feature of amino acid sequences.\n",
    "#### 2. Predicting the deep conversion value of tetra peptides with the festures of both sequence and vhse property. \n",
    "\n",
    "\n",
    "### example for model tuning and cross validation: https://towardsdatascience.com/hyperparameter-tuning-the-random-forest-in-python-using-scikit-learn-28d2aa77dd74\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: Predicting the deep conversion value of tetra peptides with only the feature of amino acid sequences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd ## Load the library\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import boxcox\n",
    "\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## read csv file into dataframe\n",
    "df = pd.read_csv (r'DataSet.csv')[:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>seq</th>\n",
       "      <th>label</th>\n",
       "      <th>log.label</th>\n",
       "      <th>z1.1</th>\n",
       "      <th>z1.2</th>\n",
       "      <th>z1.3</th>\n",
       "      <th>z2.1</th>\n",
       "      <th>z2.2</th>\n",
       "      <th>z2.3</th>\n",
       "      <th>z3.1</th>\n",
       "      <th>...</th>\n",
       "      <th>vhse3.7</th>\n",
       "      <th>vhse3.8</th>\n",
       "      <th>vhse4.1</th>\n",
       "      <th>vhse4.2</th>\n",
       "      <th>vhse4.3</th>\n",
       "      <th>vhse4.4</th>\n",
       "      <th>vhse4.5</th>\n",
       "      <th>vhse4.6</th>\n",
       "      <th>vhse4.7</th>\n",
       "      <th>vhse4.8</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TVPT</td>\n",
       "      <td>0.002273</td>\n",
       "      <td>-2.643473</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.19</td>\n",
       "      <td>3.56</td>\n",
       "      <td>-0.34</td>\n",
       "      <td>-0.51</td>\n",
       "      <td>-0.55</td>\n",
       "      <td>-1.06</td>\n",
       "      <td>-0.06</td>\n",
       "      <td>-0.01</td>\n",
       "      <td>-0.79</td>\n",
       "      <td>0.39</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>VYVY</td>\n",
       "      <td>0.002380</td>\n",
       "      <td>-2.623463</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>-2.53</td>\n",
       "      <td>-1.29</td>\n",
       "      <td>-1.39</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.01</td>\n",
       "      <td>-2.69</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.24</td>\n",
       "      <td>-0.03</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>1.17</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.25</td>\n",
       "      <td>-0.96</td>\n",
       "      <td>-0.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>KNML</td>\n",
       "      <td>0.001945</td>\n",
       "      <td>-2.711181</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.41</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>3.22</td>\n",
       "      <td>1.45</td>\n",
       "      <td>0.84</td>\n",
       "      <td>-2.49</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.86</td>\n",
       "      <td>-0.68</td>\n",
       "      <td>1.36</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>-0.80</td>\n",
       "      <td>0.22</td>\n",
       "      <td>-1.37</td>\n",
       "      <td>0.08</td>\n",
       "      <td>-0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KTIA</td>\n",
       "      <td>0.001151</td>\n",
       "      <td>-2.939057</td>\n",
       "      <td>2.84</td>\n",
       "      <td>1.41</td>\n",
       "      <td>-3.14</td>\n",
       "      <td>0.92</td>\n",
       "      <td>-2.09</td>\n",
       "      <td>-1.40</td>\n",
       "      <td>-4.44</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>-0.13</td>\n",
       "      <td>0.15</td>\n",
       "      <td>-1.11</td>\n",
       "      <td>-1.35</td>\n",
       "      <td>-0.92</td>\n",
       "      <td>0.02</td>\n",
       "      <td>-0.91</td>\n",
       "      <td>0.36</td>\n",
       "      <td>-0.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LHFR</td>\n",
       "      <td>0.002031</td>\n",
       "      <td>-2.692215</td>\n",
       "      <td>-4.19</td>\n",
       "      <td>-1.03</td>\n",
       "      <td>-0.98</td>\n",
       "      <td>2.41</td>\n",
       "      <td>1.74</td>\n",
       "      <td>1.11</td>\n",
       "      <td>-4.92</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.33</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>-1.47</td>\n",
       "      <td>1.45</td>\n",
       "      <td>1.24</td>\n",
       "      <td>1.27</td>\n",
       "      <td>1.55</td>\n",
       "      <td>1.47</td>\n",
       "      <td>1.30</td>\n",
       "      <td>0.83</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    seq     label  log.label  z1.1  z1.2  z1.3  z2.1  z2.2  z2.3  z3.1  ...  \\\n",
       "0  TVPT  0.002273  -2.643473  0.92 -2.09 -1.40 -2.69 -2.53 -1.29 -1.22  ...   \n",
       "1  VYVY  0.002380  -2.623463 -2.69 -2.53 -1.29 -1.39  2.32  0.01 -2.69  ...   \n",
       "2  KNML  0.001945  -2.711181  2.84  1.41 -3.14  3.22  1.45  0.84 -2.49  ...   \n",
       "3  KTIA  0.001151  -2.939057  2.84  1.41 -3.14  0.92 -2.09 -1.40 -4.44  ...   \n",
       "4  LHFR  0.002031  -2.692215 -4.19 -1.03 -0.98  2.41  1.74  1.11 -4.92  ...   \n",
       "\n",
       "   vhse3.7  vhse3.8  vhse4.1  vhse4.2  vhse4.3  vhse4.4  vhse4.5  vhse4.6  \\\n",
       "0    -0.19     3.56    -0.34    -0.51    -0.55    -1.06    -0.06    -0.01   \n",
       "1    -0.24    -0.03     0.61     1.60     1.17     0.73     0.53     0.25   \n",
       "2    -0.86    -0.68     1.36     0.07     0.26    -0.80     0.22    -1.37   \n",
       "3    -0.16    -0.13     0.15    -1.11    -1.35    -0.92     0.02    -0.91   \n",
       "4    -1.33    -0.20    -1.47     1.45     1.24     1.27     1.55     1.47   \n",
       "\n",
       "   vhse4.7  vhse4.8  \n",
       "0    -0.79     0.39  \n",
       "1    -0.96    -0.52  \n",
       "2     0.08    -0.62  \n",
       "3     0.36    -0.48  \n",
       "4     1.30     0.83  \n",
       "\n",
       "[5 rows x 47 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 47)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "max log likehood lambda is 0.26692380917611636\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Hist of box cox transferred label')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "new_label, lambda_val = boxcox(df.label)\n",
    "\n",
    "print(f'\\nmax log likehood lambda is {lambda_val}')\n",
    "\n",
    "plt.hist(new_label)\n",
    "plt.title('Hist of box cox transferred label')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The sequence column is converted to numerial features with dummies coder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_possible_features = pd.read_csv(\"082921_all_4mer_SMILES_features_full.csv\", index_col = 'AA')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AAAA</th>\n",
       "      <td>-0.000381</td>\n",
       "      <td>-0.001885</td>\n",
       "      <td>0.001924</td>\n",
       "      <td>-0.003132</td>\n",
       "      <td>0.000423</td>\n",
       "      <td>-0.000857</td>\n",
       "      <td>-0.002642</td>\n",
       "      <td>-0.000067</td>\n",
       "      <td>-0.001809</td>\n",
       "      <td>-0.001631</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001363</td>\n",
       "      <td>-0.000196</td>\n",
       "      <td>0.001626</td>\n",
       "      <td>-0.003016</td>\n",
       "      <td>-0.001227</td>\n",
       "      <td>-0.001046</td>\n",
       "      <td>-0.002094</td>\n",
       "      <td>-0.000144</td>\n",
       "      <td>-0.001863</td>\n",
       "      <td>0.002075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAC</th>\n",
       "      <td>0.000791</td>\n",
       "      <td>-0.001547</td>\n",
       "      <td>0.000637</td>\n",
       "      <td>-0.001947</td>\n",
       "      <td>0.001909</td>\n",
       "      <td>-0.001165</td>\n",
       "      <td>-0.001325</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>-0.002190</td>\n",
       "      <td>-0.001649</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000977</td>\n",
       "      <td>-0.000821</td>\n",
       "      <td>0.001342</td>\n",
       "      <td>-0.002938</td>\n",
       "      <td>-0.001195</td>\n",
       "      <td>-0.000953</td>\n",
       "      <td>-0.002086</td>\n",
       "      <td>-0.000111</td>\n",
       "      <td>-0.001855</td>\n",
       "      <td>0.002089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAD</th>\n",
       "      <td>-0.001672</td>\n",
       "      <td>-0.002515</td>\n",
       "      <td>0.001345</td>\n",
       "      <td>-0.000543</td>\n",
       "      <td>-0.002419</td>\n",
       "      <td>-0.000194</td>\n",
       "      <td>0.000429</td>\n",
       "      <td>-0.001601</td>\n",
       "      <td>-0.001893</td>\n",
       "      <td>-0.002710</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001182</td>\n",
       "      <td>-0.001285</td>\n",
       "      <td>0.001382</td>\n",
       "      <td>-0.003048</td>\n",
       "      <td>-0.001232</td>\n",
       "      <td>-0.000807</td>\n",
       "      <td>-0.002040</td>\n",
       "      <td>-0.000125</td>\n",
       "      <td>-0.001891</td>\n",
       "      <td>0.002168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAE</th>\n",
       "      <td>-0.001544</td>\n",
       "      <td>-0.001384</td>\n",
       "      <td>0.001366</td>\n",
       "      <td>-0.004296</td>\n",
       "      <td>-0.001292</td>\n",
       "      <td>-0.002008</td>\n",
       "      <td>-0.001376</td>\n",
       "      <td>0.000847</td>\n",
       "      <td>-0.001075</td>\n",
       "      <td>-0.001412</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001674</td>\n",
       "      <td>-0.000380</td>\n",
       "      <td>0.001804</td>\n",
       "      <td>-0.003212</td>\n",
       "      <td>-0.001305</td>\n",
       "      <td>-0.000853</td>\n",
       "      <td>-0.002025</td>\n",
       "      <td>-0.000238</td>\n",
       "      <td>-0.001931</td>\n",
       "      <td>0.002208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAAF</th>\n",
       "      <td>-0.002747</td>\n",
       "      <td>-0.003526</td>\n",
       "      <td>0.001414</td>\n",
       "      <td>-0.003065</td>\n",
       "      <td>-0.000307</td>\n",
       "      <td>0.003386</td>\n",
       "      <td>-0.000732</td>\n",
       "      <td>0.001065</td>\n",
       "      <td>-0.002273</td>\n",
       "      <td>-0.002017</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001598</td>\n",
       "      <td>-0.000547</td>\n",
       "      <td>0.001698</td>\n",
       "      <td>-0.003082</td>\n",
       "      <td>-0.001333</td>\n",
       "      <td>-0.000864</td>\n",
       "      <td>-0.002097</td>\n",
       "      <td>-0.000208</td>\n",
       "      <td>-0.001929</td>\n",
       "      <td>0.002118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "AA                                                                           \n",
       "AAAA -0.000381 -0.001885  0.001924 -0.003132  0.000423 -0.000857 -0.002642   \n",
       "AAAC  0.000791 -0.001547  0.000637 -0.001947  0.001909 -0.001165 -0.001325   \n",
       "AAAD -0.001672 -0.002515  0.001345 -0.000543 -0.002419 -0.000194  0.000429   \n",
       "AAAE -0.001544 -0.001384  0.001366 -0.004296 -0.001292 -0.002008 -0.001376   \n",
       "AAAF -0.002747 -0.003526  0.001414 -0.003065 -0.000307  0.003386 -0.000732   \n",
       "\n",
       "             7         8         9  ...       502       503       504  \\\n",
       "AA                                  ...                                 \n",
       "AAAA -0.000067 -0.001809 -0.001631  ... -0.001363 -0.000196  0.001626   \n",
       "AAAC  0.001219 -0.002190 -0.001649  ... -0.000977 -0.000821  0.001342   \n",
       "AAAD -0.001601 -0.001893 -0.002710  ... -0.001182 -0.001285  0.001382   \n",
       "AAAE  0.000847 -0.001075 -0.001412  ... -0.001674 -0.000380  0.001804   \n",
       "AAAF  0.001065 -0.002273 -0.002017  ... -0.001598 -0.000547  0.001698   \n",
       "\n",
       "           505       506       507       508       509       510       511  \n",
       "AA                                                                          \n",
       "AAAA -0.003016 -0.001227 -0.001046 -0.002094 -0.000144 -0.001863  0.002075  \n",
       "AAAC -0.002938 -0.001195 -0.000953 -0.002086 -0.000111 -0.001855  0.002089  \n",
       "AAAD -0.003048 -0.001232 -0.000807 -0.002040 -0.000125 -0.001891  0.002168  \n",
       "AAAE -0.003212 -0.001305 -0.000853 -0.002025 -0.000238 -0.001931  0.002208  \n",
       "AAAF -0.003082 -0.001333 -0.000864 -0.002097 -0.000208 -0.001929  0.002118  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_possible_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5000, 512)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data = all_possible_features.loc[df.seq]\n",
    "\n",
    "#full_data['label'] = new_label\n",
    "full_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>502</th>\n",
       "      <th>503</th>\n",
       "      <th>504</th>\n",
       "      <th>505</th>\n",
       "      <th>506</th>\n",
       "      <th>507</th>\n",
       "      <th>508</th>\n",
       "      <th>509</th>\n",
       "      <th>510</th>\n",
       "      <th>511</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AA</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>TVPT</th>\n",
       "      <td>-0.000596</td>\n",
       "      <td>0.002301</td>\n",
       "      <td>-0.000652</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.001604</td>\n",
       "      <td>-0.001402</td>\n",
       "      <td>0.002289</td>\n",
       "      <td>0.001176</td>\n",
       "      <td>-0.003125</td>\n",
       "      <td>0.006254</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000305</td>\n",
       "      <td>-0.001129</td>\n",
       "      <td>0.001191</td>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.000307</td>\n",
       "      <td>0.006096</td>\n",
       "      <td>0.001968</td>\n",
       "      <td>0.001572</td>\n",
       "      <td>-0.002310</td>\n",
       "      <td>0.002305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>VYVY</th>\n",
       "      <td>0.004424</td>\n",
       "      <td>-0.004041</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>0.003654</td>\n",
       "      <td>0.004595</td>\n",
       "      <td>0.001184</td>\n",
       "      <td>0.001205</td>\n",
       "      <td>0.000220</td>\n",
       "      <td>-0.001810</td>\n",
       "      <td>0.000437</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002275</td>\n",
       "      <td>-0.004572</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>-0.000736</td>\n",
       "      <td>-0.000153</td>\n",
       "      <td>0.000196</td>\n",
       "      <td>-0.001472</td>\n",
       "      <td>-0.001025</td>\n",
       "      <td>0.004757</td>\n",
       "      <td>0.002577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KNML</th>\n",
       "      <td>0.001620</td>\n",
       "      <td>0.000998</td>\n",
       "      <td>-0.001208</td>\n",
       "      <td>-0.000269</td>\n",
       "      <td>0.001316</td>\n",
       "      <td>-0.000020</td>\n",
       "      <td>-0.000322</td>\n",
       "      <td>-0.000925</td>\n",
       "      <td>0.000505</td>\n",
       "      <td>0.001122</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000853</td>\n",
       "      <td>0.005258</td>\n",
       "      <td>0.001031</td>\n",
       "      <td>-0.000632</td>\n",
       "      <td>-0.000205</td>\n",
       "      <td>-0.000408</td>\n",
       "      <td>-0.000687</td>\n",
       "      <td>-0.001436</td>\n",
       "      <td>0.005580</td>\n",
       "      <td>0.002802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KTIA</th>\n",
       "      <td>0.001567</td>\n",
       "      <td>0.000126</td>\n",
       "      <td>0.001578</td>\n",
       "      <td>-0.001605</td>\n",
       "      <td>0.000328</td>\n",
       "      <td>-0.003404</td>\n",
       "      <td>-0.000107</td>\n",
       "      <td>-0.002833</td>\n",
       "      <td>0.000113</td>\n",
       "      <td>-0.001666</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000433</td>\n",
       "      <td>-0.002361</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000360</td>\n",
       "      <td>-0.001018</td>\n",
       "      <td>0.002644</td>\n",
       "      <td>-0.001388</td>\n",
       "      <td>-0.001387</td>\n",
       "      <td>0.004059</td>\n",
       "      <td>0.002587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LHFR</th>\n",
       "      <td>0.000937</td>\n",
       "      <td>-0.002732</td>\n",
       "      <td>-0.001624</td>\n",
       "      <td>0.002074</td>\n",
       "      <td>-0.007026</td>\n",
       "      <td>-0.004133</td>\n",
       "      <td>-0.001269</td>\n",
       "      <td>0.004331</td>\n",
       "      <td>0.001325</td>\n",
       "      <td>0.003525</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001773</td>\n",
       "      <td>0.002510</td>\n",
       "      <td>0.004279</td>\n",
       "      <td>0.004078</td>\n",
       "      <td>-0.002431</td>\n",
       "      <td>-0.001517</td>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.002388</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.002780</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 512 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1         2         3         4         5         6  \\\n",
       "AA                                                                           \n",
       "TVPT -0.000596  0.002301 -0.000652 -0.000422 -0.001604 -0.001402  0.002289   \n",
       "VYVY  0.004424 -0.004041  0.001636  0.003654  0.004595  0.001184  0.001205   \n",
       "KNML  0.001620  0.000998 -0.001208 -0.000269  0.001316 -0.000020 -0.000322   \n",
       "KTIA  0.001567  0.000126  0.001578 -0.001605  0.000328 -0.003404 -0.000107   \n",
       "LHFR  0.000937 -0.002732 -0.001624  0.002074 -0.007026 -0.004133 -0.001269   \n",
       "\n",
       "             7         8         9  ...       502       503       504  \\\n",
       "AA                                  ...                                 \n",
       "TVPT  0.001176 -0.003125  0.006254  ... -0.000305 -0.001129  0.001191   \n",
       "VYVY  0.000220 -0.001810  0.000437  ... -0.002275 -0.004572 -0.001000   \n",
       "KNML -0.000925  0.000505  0.001122  ... -0.000853  0.005258  0.001031   \n",
       "KTIA -0.002833  0.000113 -0.001666  ... -0.000433 -0.002361  0.000092   \n",
       "LHFR  0.004331  0.001325  0.003525  ...  0.001773  0.002510  0.004279   \n",
       "\n",
       "           505       506       507       508       509       510       511  \n",
       "AA                                                                          \n",
       "TVPT  0.001863  0.000307  0.006096  0.001968  0.001572 -0.002310  0.002305  \n",
       "VYVY -0.000736 -0.000153  0.000196 -0.001472 -0.001025  0.004757  0.002577  \n",
       "KNML -0.000632 -0.000205 -0.000408 -0.000687 -0.001436  0.005580  0.002802  \n",
       "KTIA  0.000360 -0.001018  0.002644 -0.001388 -0.001387  0.004059  0.002587  \n",
       "LHFR  0.004078 -0.002431 -0.001517  0.001807  0.002388  0.000091  0.002780  \n",
       "\n",
       "[5 rows x 512 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set shape: (4000, 512)\n",
      "Training label length: 4000\n",
      "Test set shape: (1000, 512)\n",
      "Test label length: 1000\n"
     ]
    }
   ],
   "source": [
    "#split train and test dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(full_data, new_label, test_size=0.2, random_state=624)\n",
    "\n",
    "\n",
    "print(f\"Training set shape: {X_train.shape}\")\n",
    "print(f\"Training label length: {len(y_train)}\")\n",
    "\n",
    "print(f\"Test set shape: {X_test.shape}\")\n",
    "print(f\"Test label length: {len(y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([8.000e+00, 6.900e+01, 3.790e+02, 1.575e+03, 1.523e+03, 3.830e+02,\n",
       "        4.900e+01, 1.100e+01, 1.000e+00, 2.000e+00]),\n",
       " array([-1.10366762e-02, -8.26686267e-03, -5.49704917e-03, -2.72723568e-03,\n",
       "         4.25778113e-05,  2.81239130e-03,  5.58220480e-03,  8.35201829e-03,\n",
       "         1.11218318e-02,  1.38916453e-02,  1.66614588e-02]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Training dataset features are close to normal distributed\n",
    "\n",
    "plt.hist(X_train.iloc[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed:  2.5min\n",
      "/root/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:691: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 146 tasks      | elapsed: 10.0min\n",
      "[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed: 21.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FINISHED!\n",
      "Total amount of time is 1348.23 seconds.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#random forest regressor CV for parameter selection\n",
    "# Use the random grid to search for best hyperparameters\n",
    "# First create the base model to tune\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor()\n",
    "# Random search of parameters, using 5 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)\n",
    "\n",
    "end = time.time()\n",
    "\n",
    "\n",
    "print(f\"FINISHED!\\nTotal amount of time is {round(end-start, 2)} seconds.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1525,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 85,\n",
       " 'bootstrap': True}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.04317759350347782\n",
      "Model Performance\n",
      "Average Error: 0.0432 degrees.\n",
      "Accuracy = 98.58%.\n",
      "0.10098489307349238\n",
      "Model Performance\n",
      "Average Error: 0.1010 degrees.\n",
      "Accuracy = 96.68%.\n"
     ]
    }
   ],
   "source": [
    "def evaluate(model, test_features, test_labels):\n",
    "    predictions = model.predict(test_features)\n",
    "    errors = np.sqrt(np.mean(np.power(predictions - test_labels, 2)))\n",
    "    print(errors)\n",
    "    mape = 100 * np.mean(abs(errors / test_labels))\n",
    "    accuracy = 100 - mape\n",
    "    print('Model Performance')\n",
    "    print('Average Error: {:0.4f} degrees.'.format(np.mean(errors)))\n",
    "    print('Accuracy = {:0.2f}%.'.format(accuracy))\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "\n",
    "#accuracy with base model\n",
    "\n",
    "base_model = RandomForestRegressor(n_estimators = 10, random_state = 42)\n",
    "base_model.fit(X_train, y_train)\n",
    "\n",
    "base_accuracy_train = evaluate(base_model, X_train, y_train)\n",
    "base_accuracy_test = evaluate(base_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.03556428799148597\n",
      "Model Performance\n",
      "Average Error: 0.0356 degrees.\n",
      "Accuracy = 98.83%.\n",
      "0.09801839937456745\n",
      "Model Performance\n",
      "Average Error: 0.0980 degrees.\n",
      "Accuracy = 96.78%.\n",
      "Improvement of 0.10%.\n"
     ]
    }
   ],
   "source": [
    "#accurary with randon searched best model\n",
    "best_random = rf_random.best_estimator_\n",
    "\n",
    "random_accuracy_train = evaluate(best_random, X_train, y_train)\n",
    "random_accuracy_test = evaluate(best_random, X_test, y_test)\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (random_accuracy_test - base_accuracy_test) / base_accuracy_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#narrow the search \n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [80, 90, 100],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [3, 4, 5],\n",
    "    'min_samples_split': [8, 10, 12],\n",
    "    'n_estimators': [100, 200, 300, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = random_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_features = best_random.predict(all_possible_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-2.7738424668877646\n",
      "-3.273038709604433\n"
     ]
    }
   ],
   "source": [
    "max_pre = max(all_features)\n",
    "\n",
    "min_pre = min(all_features)\n",
    "\n",
    "print(max(all_features))\n",
    "print(min(all_features))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original max is 0.006393367066790137\n",
      "original min is 0.0004306530908746068\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "orign_label_max = np.power((max_pre*lambda_val+1), 1/lambda_val)\n",
    "\n",
    "orign_label_min = np.power((min_pre*lambda_val+1), 1/lambda_val)\n",
    "\n",
    "\n",
    "print(f\"original max is {orign_label_max}\")\n",
    "print(f\"original min is {orign_label_min}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.06379396007287808\n",
      "Model Performance\n",
      "Average Error: 0.0638 degrees.\n",
      "Accuracy = 97.91%.\n",
      "0.10228865029433992\n",
      "Model Performance\n",
      "Average Error: 0.1023 degrees.\n",
      "Accuracy = 96.64%.\n",
      "Improvement of -0.04%.\n"
     ]
    }
   ],
   "source": [
    "best_grid = grid_search.best_estimator_\n",
    "\n",
    "grid_accuracy_train = evaluate(best_grid, X_train, y_train)\n",
    "grid_accuracy_test = evaluate(best_grid, X_test, y_test)\n",
    "print('Improvement of {:0.2f}%.'.format( 100 * (grid_accuracy_test - base_accuracy_test) / base_accuracy_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New dataframe with converted sequence feature is merged. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge1=pd.merge(df1,df2,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge2=pd.merge(df3,df4,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge3=pd.merge(df_merge1,df_merge2,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5=df[['label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge=pd.merge(df_merge3,df5,left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merge.drop(['s1', 's2','s3','s4','label'], axis=1)\n",
    "y = df_merge.label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random forest regressor model is used to train and test the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3) # 70% training and 30% test\n",
    "#Build RF model\n",
    "RFR = RandomForestRegressor(n_estimators=150, random_state=0)\n",
    "\n",
    "#Randomly spilt dataset to test and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3 )\n",
    "#Train RFR\n",
    "RFR.fit(X_train, y_train)\n",
    "#RFR prediction result\n",
    "y_pred = RFR.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RFR.predict(X_test[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A function is defined to inverted converting the dummy code to amino acid sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def undummify(df, prefix_sep=\"_\"):\n",
    "    cols2collapse = {\n",
    "        item.split(prefix_sep)[0]: (prefix_sep in item) for item in df.columns\n",
    "    }\n",
    "    series_list = []\n",
    "    for col, needs_to_collapse in cols2collapse.items():\n",
    "        if needs_to_collapse:\n",
    "            undummified = (\n",
    "                df.filter(like=col)\n",
    "                .idxmax(axis=1)\n",
    "                .apply(lambda x: x.split(prefix_sep, maxsplit=1)[1])\n",
    "                .rename(col)\n",
    "            )\n",
    "            series_list.append(undummified)\n",
    "        else:\n",
    "            series_list.append(df[col])\n",
    "    undummified_df = pd.concat(series_list, axis=1)\n",
    "    return undummified_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Re = undummify(X_test[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Re.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RFR.predict(X_test[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a plot to compare the actual and predicted DC values for the first 50 test rows. \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df_comparison.Actual.head(50)\n",
    "y = df_comparison.Predicted.head(50)\n",
    "\n",
    "plt.plot(x, y, 'o', color='black');\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to input a tetra peptide sequence and predict the DC value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### This module is used to converted nested list to a flatten one. \n",
    "def flatten(x):\n",
    "    result = []\n",
    "    for el in x:\n",
    "        if hasattr(el, \"__iter__\") and not isinstance(el, str):\n",
    "            result.extend(flatten(el))\n",
    "        else:\n",
    "            result.append(el)\n",
    "    return result\n",
    "\n",
    "print(flatten([\"junk\",[\"nested stuff\"],[],[[]]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "# define input string\n",
    "data = input(\"Enter four amino acid:-\")\n",
    "print(data)\n",
    "# define universe of possible input values\n",
    "alphabet = 'acdefghiklmnpqrstvwy'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# integer encode input data\n",
    "integer_encoded = [char_to_int[char] for char in data]\n",
    "print(integer_encoded)\n",
    "# one hot encode\n",
    "onehot_encoded = []\n",
    "L=[]\n",
    "for value in integer_encoded:\n",
    "\tletter = [0 for _ in range(len(alphabet))]\n",
    "\tletter[value] = 1\n",
    "\tonehot_encoded.append(letter)\n",
    "print(onehot_encoded)\n",
    "L= flatten(onehot_encoded)\n",
    "# calculate DC value\n",
    "print(RFR.predict([L])) ## Predict the DC value with amino acid sequence. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2. Predicting the DC value of tetra peptides with the festures of both sequence and vhse property. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse = pd.read_excel (r'C:\\Users\\wu2\\48Dis\\vhse.xlsx') ##load the vhse code for amino acid. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse['vhse1'] = df_vhse['vhse1'].str.replace('[^\\x00-\\x7F]+','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_vhse['vhse2'] = df_vhse['vhse2'].str.replace('[^\\x00-\\x7F]+','-')\n",
    "df_vhse['vhse3'] = df_vhse['vhse3'].str.replace('[^\\x00-\\x7F]+','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse['vhse4'] = df_vhse['vhse4'].str.replace('[^\\x00-\\x7F]+','-')\n",
    "df_vhse['vhse5'] = df_vhse['vhse5'].str.replace('[^\\x00-\\x7F]+','-')\n",
    "df_vhse['vhse6'] = df_vhse['vhse6'].str.replace('[^\\x00-\\x7F]+','-')\n",
    "df_vhse['vhse7'] = df_vhse['vhse7'].str.replace('[^\\x00-\\x7F]+','-')\n",
    "df_vhse['vhse8'] = df_vhse['vhse8'].str.replace('[^\\x00-\\x7F]+','-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_vhse['vhse2'] = df_vhse['vhse2'].astype(np.float64)\n",
    "df_vhse['vhse3'] = df_vhse['vhse3'].astype(np.float64)\n",
    "df_vhse['vhse4'] = df_vhse['vhse4'].astype(np.float64)\n",
    "df_vhse['vhse5'] = df_vhse['vhse5'].astype(np.float64)\n",
    "df_vhse['vhse6'] = df_vhse['vhse6'].astype(np.float64)\n",
    "df_vhse['vhse7'] = df_vhse['vhse7'].astype(np.float64)\n",
    "df_vhse['vhse8'] = df_vhse['vhse8'].astype(np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse.drop(['vhse_code'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse['code'] = df_vhse[df_vhse.columns[1:]].apply(lambda x: ','.join(x.dropna().astype(str)),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vhse.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This module is a practise to convert a amino acid into its vhse values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Find a way to convert input amino acid to vhse code. \n",
    "rename_dict = df_vhse.set_index('seq').to_dict()['code']\n",
    "A1 = input(\"Provide A1 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A1:\n",
    "        l1=code\n",
    "        print(l1)\n",
    "A2 = input(\"Provide A2 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A2:\n",
    "        l2=code\n",
    "        print(l2)\n",
    "A3 = input(\"Provide A3 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A3:\n",
    "        l3=code\n",
    "A4 = input(\"Provide A4 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A4:\n",
    "        l4=code \n",
    "        l5=l1+l2+l3+l4\n",
    "        print(l5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Start building a dataframe with the vhse properties from the original dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_n_column  = df.iloc[: , -32:] # Get those columns of vhse values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_n_column.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_vhse=pd.merge(df_merge3,last_n_column,left_index=True, right_index=True)#merge sequence with vhse features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_vhse=pd.merge(df_merge_vhse,df5,left_index=True, right_index=True)# merge features with the label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merge_vhse.head() ## A new dataframe with both sequence and vhse features. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use both amino acid sequence and vhse as features for data training and model building. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_merge_vhse.drop(['s1', 's2','s3','s4','label'], axis=1) # set the features for training\n",
    "y = df_merge_vhse.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Build RF model\n",
    "RFR2 = RandomForestRegressor(n_estimators=150, random_state=0)# Build 150 decision tree. \n",
    "\n",
    "#Randomly spilt dataset to test and train set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3 ) # Split training and test dataset, where 30 % used for testing. \n",
    "#Train RFR\n",
    "RFR2.fit(X_train, y_train)\n",
    "#RFR prediction result\n",
    "y_pred = RFR2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(RFR2.predict(X_test[:5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_comparison2 = pd.DataFrame({'Actual': y_test, 'Predicted': y_pred})\n",
    "df_comparison2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Make a plot to compare the actual and predicted DC values for the first 80 test rows. \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x = df_comparison2.Actual.head(80)\n",
    "y = df_comparison2.Predicted.head(80)\n",
    "plt.figure(figsize=(6,6))\n",
    "plt.plot(x, y, 'o', color='blue');\n",
    "plt.xlabel(\"Actual\")\n",
    "plt.ylabel(\"Predicted\")\n",
    "plt.xlim(0, 0.006)\n",
    "plt.ylim(0, 0.006)\n",
    "plt.plot([0, 1], [0, 1], color = 'black', linewidth = 2)\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try to input a tetra peptide sequence and predict the DC value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import argmax\n",
    "# define input string \n",
    "data = input(\"Enter four amino acid:-\")\n",
    "print(data)\n",
    "# define universe of possible input values\n",
    "alphabet = 'acdefghiklmnpqrstvwy'\n",
    "# define a mapping of chars to integers\n",
    "char_to_int = dict((c, i) for i, c in enumerate(alphabet))\n",
    "int_to_char = dict((i, c) for i, c in enumerate(alphabet))\n",
    "# integer encode input data\n",
    "integer_encoded = [char_to_int[char] for char in data]\n",
    "print(integer_encoded)\n",
    "# one hot encode\n",
    "onehot_encoded = []\n",
    "L=[]\n",
    "test=[]\n",
    "l6=[]\n",
    "l1=[]\n",
    "l2=[]\n",
    "l3=[]\n",
    "l4=[]\n",
    "for value in integer_encoded:\n",
    "\tletter = [0 for _ in range(len(alphabet))]\n",
    "\tletter[value] = 1\n",
    "\tonehot_encoded.append(letter)\n",
    "print(onehot_encoded)\n",
    "L= flatten(onehot_encoded) ## Get the list of one hote code of amino acids\n",
    "A1 = input(\"Provide A1 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A1:\n",
    "        l1=code.split(',')\n",
    "        print(l1)\n",
    "A2 = input(\"Provide A2 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A2:\n",
    "        l2=code.split(',')\n",
    "        print(l2)\n",
    "A3 = input(\"Provide A3 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A3:\n",
    "        l3=code.split(',')\n",
    "A4 = input(\"Provide A4 \")\n",
    "for name, code in rename_dict.items():  # for name, code in dictionary.iteritems():  \n",
    "    if name == A4:\n",
    "        l4=code.split(',')\n",
    "        l5=l1+l2+l3+l4\n",
    "print(l5)\n",
    "test_str =l5\n",
    "res = [float(idx) for idx in test_str]\n",
    "print(res)\n",
    "test=L+res\n",
    "print(test)\n",
    "print(RFR2.predict([test]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "#### One hot encoder method is used to convert the protein sequence into numerical features.  \n",
    "#### Random forest regressor model was built for predicting the DC value from amino acid sequence with or without the vhse properties. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
